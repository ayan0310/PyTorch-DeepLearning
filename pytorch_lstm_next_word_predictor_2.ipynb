{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfcpnluzLzo",
        "outputId": "0e69368e-1ac3-404d-d94f-7cfcf4428349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\" As we descend from the sunlit surface into the abyss, the environment undergoes radical transformations. The ocean is layered like a subterranean cake, with each stratum hosting its own unique ecosystem.\n",
        "\n",
        "The Epipelagic Zone (Sunlight Zone): Stretching from the surface down to about 200 meters, this is the zone we are most familiar with. It is flooded with sunlight, allowing photosynthesis to occur. Here, phytoplankton form the base of the global marine food web, supporting everything from tiny krill to massive blue whales.\n",
        "\n",
        "The Mesopelagic Zone (Twilight Zone): Extending from 200 to 1,000 meters, this zone receives only a faint, ethereal glow of sunlight, enough to see by, but not enough to sustain photosynthesis. Animals here rely heavily on marine snow, a continuous shower of organic detritus falling from the productive waters above. This zone is famous for its vertical migrators; billions of creatures travel to the surface at night to feed and retreat to the safety of the twilight zone during the day, making it the largest mass migration on Earth.\n",
        "\n",
        "The Bathypelagic Zone (Midnight Zone): From 1,000 to 4,000 meters, we enter a world devoid of solar light. The only illumination here comes from bioluminescence, light produced by the animals themselves. The pressure is immense, exceeding 5,800 pounds per square inch. Food is incredibly scarce.\n",
        "\n",
        "The Abyssopelagic Zone (The Abyss): Stretching from 4,000 to 6,000 meters, the abyssal zone covers the vast, flat plains of the ocean floor. The water is near freezing, and the pressure is bone-crushing. Yet, life persists in the form of deep-sea cucumbers, brittle stars, and scavenging amphipods.\n",
        "\n",
        "The Hadalpelagic Zone (The Trenches): The deepest parts of the ocean, extending from 6,000 meters to the very bottom of the Mariana Trench at nearly 11,000 meters. Named after Hades, the Greek god of the underworld, this zone is confined to deep tectonic trenches.\n",
        "\n",
        "The sea, once it casts its spell, holds one in its net of wonder forever. Jacques Yves Cousteau\n",
        "\n",
        "Bioluminescence: The Living Light\n",
        "\n",
        "In the pitch-black void of the bathypelagic and abyssopelagic zones, vision would seem to be a useless sense. Yet, many deep-sea creatures possess highly developed, incredibly sensitive eyes. This is because the deep ocean is not entirely dark; it is illuminated by the flashes, pulses, and steady glows of bioluminescence.\n",
        "\n",
        "Bioluminescence is the biochemical emission of light by living organisms. In the deep sea, it is estimated that up to ninety percent of the animals possess this remarkable ability. It serves a multitude of vital functions in an environment where finding a mate, securing a meal, or avoiding a predator is overwhelmingly difficult.\n",
        "\n",
        "Some creatures use bioluminescence as a lure. The iconic deep-sea anglerfish dangles a glowing appendage, an esca filled with bioluminescent bacteria, in front of its massive, toothy maw to attract unwary prey. Others use it for defense. The vampire squid, when threatened, ejects a cloud of glowing, sticky mucus to confuse predators and facilitate an escape. Certain species of shrimp can vomit light to blind their attackers temporarily. Furthermore, many deep-sea fish possess photophores (light-producing organs) on their bellies. By matching the faint downwelling light from the surface, they camouflage their silhouettes from predators lurking below, a sophisticated technique known as counter-illumination.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "fLwm0Y_MzVuh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "da224014-a218-4ac8-eea1-e5f2189a7efe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "6a35252f-4d6a-476e-975a-8a4928114885"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'as': 1,\n",
              " 'we': 2,\n",
              " 'descend': 3,\n",
              " 'from': 4,\n",
              " 'the': 5,\n",
              " 'sunlit': 6,\n",
              " 'surface': 7,\n",
              " 'into': 8,\n",
              " 'abyss': 9,\n",
              " ',': 10,\n",
              " 'environment': 11,\n",
              " 'undergoes': 12,\n",
              " 'radical': 13,\n",
              " 'transformations': 14,\n",
              " '.': 15,\n",
              " 'ocean': 16,\n",
              " 'is': 17,\n",
              " 'layered': 18,\n",
              " 'like': 19,\n",
              " 'a': 20,\n",
              " 'subterranean': 21,\n",
              " 'cake': 22,\n",
              " 'with': 23,\n",
              " 'each': 24,\n",
              " 'stratum': 25,\n",
              " 'hosting': 26,\n",
              " 'its': 27,\n",
              " 'own': 28,\n",
              " 'unique': 29,\n",
              " 'ecosystem': 30,\n",
              " 'epipelagic': 31,\n",
              " 'zone': 32,\n",
              " '(': 33,\n",
              " 'sunlight': 34,\n",
              " ')': 35,\n",
              " ':': 36,\n",
              " 'stretching': 37,\n",
              " 'down': 38,\n",
              " 'to': 39,\n",
              " 'about': 40,\n",
              " '200': 41,\n",
              " 'meters': 42,\n",
              " 'this': 43,\n",
              " 'are': 44,\n",
              " 'most': 45,\n",
              " 'familiar': 46,\n",
              " 'it': 47,\n",
              " 'flooded': 48,\n",
              " 'allowing': 49,\n",
              " 'photosynthesis': 50,\n",
              " 'occur': 51,\n",
              " 'here': 52,\n",
              " 'phytoplankton': 53,\n",
              " 'form': 54,\n",
              " 'base': 55,\n",
              " 'of': 56,\n",
              " 'global': 57,\n",
              " 'marine': 58,\n",
              " 'food': 59,\n",
              " 'web': 60,\n",
              " 'supporting': 61,\n",
              " 'everything': 62,\n",
              " 'tiny': 63,\n",
              " 'krill': 64,\n",
              " 'massive': 65,\n",
              " 'blue': 66,\n",
              " 'whales': 67,\n",
              " 'mesopelagic': 68,\n",
              " 'twilight': 69,\n",
              " 'extending': 70,\n",
              " '1,000': 71,\n",
              " 'receives': 72,\n",
              " 'only': 73,\n",
              " 'faint': 74,\n",
              " 'ethereal': 75,\n",
              " 'glow': 76,\n",
              " 'enough': 77,\n",
              " 'see': 78,\n",
              " 'by': 79,\n",
              " 'but': 80,\n",
              " 'not': 81,\n",
              " 'sustain': 82,\n",
              " 'animals': 83,\n",
              " 'rely': 84,\n",
              " 'heavily': 85,\n",
              " 'on': 86,\n",
              " 'snow': 87,\n",
              " 'continuous': 88,\n",
              " 'shower': 89,\n",
              " 'organic': 90,\n",
              " 'detritus': 91,\n",
              " 'falling': 92,\n",
              " 'productive': 93,\n",
              " 'waters': 94,\n",
              " 'above': 95,\n",
              " 'famous': 96,\n",
              " 'for': 97,\n",
              " 'vertical': 98,\n",
              " 'migrators': 99,\n",
              " ';': 100,\n",
              " 'billions': 101,\n",
              " 'creatures': 102,\n",
              " 'travel': 103,\n",
              " 'at': 104,\n",
              " 'night': 105,\n",
              " 'feed': 106,\n",
              " 'and': 107,\n",
              " 'retreat': 108,\n",
              " 'safety': 109,\n",
              " 'during': 110,\n",
              " 'day': 111,\n",
              " 'making': 112,\n",
              " 'largest': 113,\n",
              " 'mass': 114,\n",
              " 'migration': 115,\n",
              " 'earth': 116,\n",
              " 'bathypelagic': 117,\n",
              " 'midnight': 118,\n",
              " '4,000': 119,\n",
              " 'enter': 120,\n",
              " 'world': 121,\n",
              " 'devoid': 122,\n",
              " 'solar': 123,\n",
              " 'light': 124,\n",
              " 'illumination': 125,\n",
              " 'comes': 126,\n",
              " 'bioluminescence': 127,\n",
              " 'produced': 128,\n",
              " 'themselves': 129,\n",
              " 'pressure': 130,\n",
              " 'immense': 131,\n",
              " 'exceeding': 132,\n",
              " '5,800': 133,\n",
              " 'pounds': 134,\n",
              " 'per': 135,\n",
              " 'square': 136,\n",
              " 'inch': 137,\n",
              " 'incredibly': 138,\n",
              " 'scarce': 139,\n",
              " 'abyssopelagic': 140,\n",
              " '6,000': 141,\n",
              " 'abyssal': 142,\n",
              " 'covers': 143,\n",
              " 'vast': 144,\n",
              " 'flat': 145,\n",
              " 'plains': 146,\n",
              " 'floor': 147,\n",
              " 'water': 148,\n",
              " 'near': 149,\n",
              " 'freezing': 150,\n",
              " 'bone-crushing': 151,\n",
              " 'yet': 152,\n",
              " 'life': 153,\n",
              " 'persists': 154,\n",
              " 'in': 155,\n",
              " 'deep-sea': 156,\n",
              " 'cucumbers': 157,\n",
              " 'brittle': 158,\n",
              " 'stars': 159,\n",
              " 'scavenging': 160,\n",
              " 'amphipods': 161,\n",
              " 'hadalpelagic': 162,\n",
              " 'trenches': 163,\n",
              " 'deepest': 164,\n",
              " 'parts': 165,\n",
              " 'very': 166,\n",
              " 'bottom': 167,\n",
              " 'mariana': 168,\n",
              " 'trench': 169,\n",
              " 'nearly': 170,\n",
              " '11,000': 171,\n",
              " 'named': 172,\n",
              " 'after': 173,\n",
              " 'hades': 174,\n",
              " 'greek': 175,\n",
              " 'god': 176,\n",
              " 'underworld': 177,\n",
              " 'confined': 178,\n",
              " 'deep': 179,\n",
              " 'tectonic': 180,\n",
              " 'sea': 181,\n",
              " 'once': 182,\n",
              " 'casts': 183,\n",
              " 'spell': 184,\n",
              " 'holds': 185,\n",
              " 'one': 186,\n",
              " 'net': 187,\n",
              " 'wonder': 188,\n",
              " 'forever': 189,\n",
              " 'jacques': 190,\n",
              " 'yves': 191,\n",
              " 'cousteau': 192,\n",
              " 'living': 193,\n",
              " 'pitch-black': 194,\n",
              " 'void': 195,\n",
              " 'zones': 196,\n",
              " 'vision': 197,\n",
              " 'would': 198,\n",
              " 'seem': 199,\n",
              " 'be': 200,\n",
              " 'useless': 201,\n",
              " 'sense': 202,\n",
              " 'many': 203,\n",
              " 'possess': 204,\n",
              " 'highly': 205,\n",
              " 'developed': 206,\n",
              " 'sensitive': 207,\n",
              " 'eyes': 208,\n",
              " 'because': 209,\n",
              " 'entirely': 210,\n",
              " 'dark': 211,\n",
              " 'illuminated': 212,\n",
              " 'flashes': 213,\n",
              " 'pulses': 214,\n",
              " 'steady': 215,\n",
              " 'glows': 216,\n",
              " 'biochemical': 217,\n",
              " 'emission': 218,\n",
              " 'organisms': 219,\n",
              " 'estimated': 220,\n",
              " 'that': 221,\n",
              " 'up': 222,\n",
              " 'ninety': 223,\n",
              " 'percent': 224,\n",
              " 'remarkable': 225,\n",
              " 'ability': 226,\n",
              " 'serves': 227,\n",
              " 'multitude': 228,\n",
              " 'vital': 229,\n",
              " 'functions': 230,\n",
              " 'an': 231,\n",
              " 'where': 232,\n",
              " 'finding': 233,\n",
              " 'mate': 234,\n",
              " 'securing': 235,\n",
              " 'meal': 236,\n",
              " 'or': 237,\n",
              " 'avoiding': 238,\n",
              " 'predator': 239,\n",
              " 'overwhelmingly': 240,\n",
              " 'difficult': 241,\n",
              " 'some': 242,\n",
              " 'use': 243,\n",
              " 'lure': 244,\n",
              " 'iconic': 245,\n",
              " 'anglerfish': 246,\n",
              " 'dangles': 247,\n",
              " 'glowing': 248,\n",
              " 'appendage': 249,\n",
              " 'esca': 250,\n",
              " 'filled': 251,\n",
              " 'bioluminescent': 252,\n",
              " 'bacteria': 253,\n",
              " 'front': 254,\n",
              " 'toothy': 255,\n",
              " 'maw': 256,\n",
              " 'attract': 257,\n",
              " 'unwary': 258,\n",
              " 'prey': 259,\n",
              " 'others': 260,\n",
              " 'defense': 261,\n",
              " 'vampire': 262,\n",
              " 'squid': 263,\n",
              " 'when': 264,\n",
              " 'threatened': 265,\n",
              " 'ejects': 266,\n",
              " 'cloud': 267,\n",
              " 'sticky': 268,\n",
              " 'mucus': 269,\n",
              " 'confuse': 270,\n",
              " 'predators': 271,\n",
              " 'facilitate': 272,\n",
              " 'escape': 273,\n",
              " 'certain': 274,\n",
              " 'species': 275,\n",
              " 'shrimp': 276,\n",
              " 'can': 277,\n",
              " 'vomit': 278,\n",
              " 'blind': 279,\n",
              " 'their': 280,\n",
              " 'attackers': 281,\n",
              " 'temporarily': 282,\n",
              " 'furthermore': 283,\n",
              " 'fish': 284,\n",
              " 'photophores': 285,\n",
              " 'light-producing': 286,\n",
              " 'organs': 287,\n",
              " 'bellies': 288,\n",
              " 'matching': 289,\n",
              " 'downwelling': 290,\n",
              " 'they': 291,\n",
              " 'camouflage': 292,\n",
              " 'silhouettes': 293,\n",
              " 'lurking': 294,\n",
              " 'below': 295,\n",
              " 'sophisticated': 296,\n",
              " 'technique': 297,\n",
              " 'known': 298,\n",
              " 'counter-illumination': 299}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOOEZ94P0dQ1",
        "outputId": "e091eb36-f189-4f9c-ce81-99430a2af89f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "RefNavJe1Cva"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n"
      ],
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))\n"
      ],
      "metadata": {
        "id": "eu66Zo3e1Wh9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxJesAQC1et3",
        "outputId": "df1b5900-10f4-4813-ebdf-efd6ae90fac7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aGJ0fy7swk",
        "outputId": "c2fde257-7fa3-4ba0-f029-34d7bbf59a9c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "618"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrFzZ4DD8Anu",
        "outputId": "39587387-8811-473a-cac3-6c0b6430f10a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "3d631245-399b-401e-a066-a0d7de2bdcf5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bIcIRd088EN",
        "outputId": "ebb71bbf-7fa1-44b5-8d31-c5069f5ba6f8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZssF989X-4",
        "outputId": "aba47e45-7436-481d-e346-d8c001ccbb0b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKvdXa79yxV",
        "outputId": "7a345e23-f693-45da-d911-7130c7dd8d83"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   2,   3,   4],\n",
              "        ...,\n",
              "        [  0,   0, 242,  ..., 297, 298,   1],\n",
              "        [  0, 242, 102,  ..., 298,   1, 299],\n",
              "        [242, 102, 243,  ...,   1, 299,  15]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "Tz8fwCok90m0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "39f17f16-8191-49b5-d4fb-e2c7ba278c71"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        ...,\n",
              "        [  0,   0, 242,  ..., 296, 297, 298],\n",
              "        [  0, 242, 102,  ..., 297, 298,   1],\n",
              "        [242, 102, 243,  ..., 298,   1, 299]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "5af93cb7-f33f-4559-ef60-b7ca0cf22815"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   4,   5,   6,   7,   8,   5,   9,  10,   5,  11,  12,  13,\n",
              "         14,  15,   5,  16,  17,  18,  19,  20,  21,  22,  10,  23,  24,  25,\n",
              "         26,  27,  28,  29,  30,  15,  31,  32,  33,  34,  32,  35,  36,  37,\n",
              "          4,   5,   7,  38,  39,  40,  41,  42,  10,  43,  17,   5,  32,   2,\n",
              "         44,  45,  46,  23,  15,  47,  17,  48,  23,  34,  10,  49,  50,  39,\n",
              "         51,  15,  52,  10,  53,  54,   5,  55,  56,   5,  57,  58,  59,  60,\n",
              "         10,  61,  62,   4,  63,  64,  39,  65,  66,  67,  15,  68,  32,  33,\n",
              "         69,  32,  35,  36,  70,   4,  41,  39,  71,  42,  10,  43,  32,  72,\n",
              "         73,  20,  74,  10,  75,  76,  56,  34,  10,  77,  39,  78,  79,  10,\n",
              "         80,  81,  77,  39,  82,  50,  15,  83,  52,  84,  85,  86,  58,  87,\n",
              "         10,  20,  88,  89,  56,  90,  91,  92,   4,   5,  93,  94,  95,  15,\n",
              "         43,  32,  17,  96,  97,  27,  98,  99, 100, 101,  56, 102, 103,  39,\n",
              "          5,   7, 104, 105,  39, 106, 107, 108,  39,   5, 109,  56,   5,  69,\n",
              "         32, 110,   5, 111,  10, 112,  47,   5, 113, 114, 115,  86, 116,  15,\n",
              "        117,  32,  33, 118,  32,  35,  36,   4,  71,  39, 119,  42,  10,   2,\n",
              "        120,  20, 121, 122,  56, 123, 124,  15,   5,  73, 125,  52, 126,   4,\n",
              "        127,  10, 124, 128,  79,   5,  83, 129,  15,   5, 130,  17, 131,  10,\n",
              "        132, 133, 134, 135, 136, 137,  15,  59,  17, 138, 139,  15, 140,  32,\n",
              "         33,   5,   9,  35,  36,  37,   4, 119,  39, 141,  42,  10,   5, 142,\n",
              "         32, 143,   5, 144,  10, 145, 146,  56,   5,  16, 147,  15,   5, 148,\n",
              "         17, 149, 150,  10, 107,   5, 130,  17, 151,  15, 152,  10, 153, 154,\n",
              "        155,   5,  54,  56, 156, 157,  10, 158, 159,  10, 107, 160, 161,  15,\n",
              "        162,  32,  33,   5, 163,  35,  36,   5, 164, 165,  56,   5,  16,  10,\n",
              "         70,   4, 141,  42,  39,   5, 166, 167,  56,   5, 168, 169, 104, 170,\n",
              "        171,  42,  15, 172, 173, 174,  10,   5, 175, 176,  56,   5, 177,  10,\n",
              "         43,  32,  17, 178,  39, 179, 180, 163,  15, 181,  10, 182,  47, 183,\n",
              "         27, 184,  10, 185, 186, 155,  27, 187,  56, 188, 189,  15, 190, 191,\n",
              "        192,  36,   5, 193, 124,   5, 194, 195,  56,   5, 117, 107, 140, 196,\n",
              "         10, 197, 198, 199,  39, 200,  20, 201, 202,  15, 152,  10, 203, 156,\n",
              "        102, 204, 205, 206,  10, 138, 207, 208,  15,  43,  17, 209,   5, 179,\n",
              "         16,  17,  81, 210, 211, 100,  47,  17, 212,  79,   5, 213,  10, 214,\n",
              "         10, 107, 215, 216,  56, 127,  15,  17,   5, 217, 218,  56, 124,  79,\n",
              "        193, 219,  15, 155,   5, 179, 181,  10,  47,  17, 220, 221, 222,  39,\n",
              "        223, 224,  56,   5,  83, 204,  43, 225, 226,  15,  47, 227,  20, 228,\n",
              "         56, 229, 230, 155, 231,  11, 232, 233,  20, 234,  10, 235,  20, 236,\n",
              "         10, 237, 238,  20, 239,  17, 240, 241,  15, 102, 243, 127,   1,  20,\n",
              "        244,  15,   5, 245, 156, 246, 247,  20, 248, 249,  10, 231, 250, 251,\n",
              "         23, 252, 253,  10, 155, 254,  56,  27,  65,  10, 255, 256,  39, 257,\n",
              "        258, 259,  15, 260, 243,  47,  97, 261,  15,   5, 262, 263,  10, 264,\n",
              "        265,  10, 266,  20, 267,  56, 248,  10, 268, 269,  39, 270, 271, 107,\n",
              "        272, 231, 273,  15, 274, 275,  56, 276, 277, 278, 124,  39, 279, 280,\n",
              "        281, 282,  15, 283,  10, 203, 156, 284, 204, 285,  33, 286, 287,  35,\n",
              "         86, 280, 288,  15,  79, 289,   5,  74, 290, 124,   4,   5,   7,  10,\n",
              "        291, 292, 280, 293,   4, 271, 294, 295,  10,  20, 296, 297, 298,   1,\n",
              "        299,  15])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHaeSuI_nJX",
        "outputId": "980b1265-fb48-474d-ee51-764ad1112802"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "618"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "7ZUeD3l6_oZ3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Lvm7W6L1X6P1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwq43NRYD3q",
        "outputId": "f4def26e-96e7-4e81-d3fc-af5f92fb95ad"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(300, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=300, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1faORN1VYFdu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "81484b93-6598-40a4-f5c7-37eba2e50be8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 113.5282\n",
            "Epoch: 2, Loss: 105.8587\n",
            "Epoch: 3, Loss: 97.2871\n",
            "Epoch: 4, Loss: 90.2559\n",
            "Epoch: 5, Loss: 83.9738\n",
            "Epoch: 6, Loss: 77.9954\n",
            "Epoch: 7, Loss: 71.6400\n",
            "Epoch: 8, Loss: 64.3951\n",
            "Epoch: 9, Loss: 58.8312\n",
            "Epoch: 10, Loss: 52.0456\n",
            "Epoch: 11, Loss: 47.0552\n",
            "Epoch: 12, Loss: 41.9740\n",
            "Epoch: 13, Loss: 36.3755\n",
            "Epoch: 14, Loss: 32.5346\n",
            "Epoch: 15, Loss: 28.0110\n",
            "Epoch: 16, Loss: 24.4513\n",
            "Epoch: 17, Loss: 21.3131\n",
            "Epoch: 18, Loss: 19.0059\n",
            "Epoch: 19, Loss: 16.7344\n",
            "Epoch: 20, Loss: 14.4166\n",
            "Epoch: 21, Loss: 12.7407\n",
            "Epoch: 22, Loss: 11.1720\n",
            "Epoch: 23, Loss: 10.0528\n",
            "Epoch: 24, Loss: 9.1421\n",
            "Epoch: 25, Loss: 8.0766\n",
            "Epoch: 26, Loss: 7.3309\n",
            "Epoch: 27, Loss: 6.6140\n",
            "Epoch: 28, Loss: 6.0949\n",
            "Epoch: 29, Loss: 5.6143\n",
            "Epoch: 30, Loss: 5.2002\n",
            "Epoch: 31, Loss: 4.7441\n",
            "Epoch: 32, Loss: 4.4365\n",
            "Epoch: 33, Loss: 4.1377\n",
            "Epoch: 34, Loss: 3.8792\n",
            "Epoch: 35, Loss: 3.6525\n",
            "Epoch: 36, Loss: 3.4983\n",
            "Epoch: 37, Loss: 3.2166\n",
            "Epoch: 38, Loss: 3.1637\n",
            "Epoch: 39, Loss: 2.8367\n",
            "Epoch: 40, Loss: 2.8231\n",
            "Epoch: 41, Loss: 2.6314\n",
            "Epoch: 42, Loss: 2.4344\n",
            "Epoch: 43, Loss: 2.3133\n",
            "Epoch: 44, Loss: 2.2233\n",
            "Epoch: 45, Loss: 2.1195\n",
            "Epoch: 46, Loss: 2.0458\n",
            "Epoch: 47, Loss: 1.9618\n",
            "Epoch: 48, Loss: 1.8927\n",
            "Epoch: 49, Loss: 1.9630\n",
            "Epoch: 50, Loss: 1.7520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "\n",
        "def prediction(model, vocab, text):\n",
        "\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  # text -> numerical indices\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  # predicted index\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[index]\n",
        "\n"
      ],
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"The course follows a monthly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VsRgcJysbGCg",
        "outputId": "81ee5cf1-86e2-4c50-9f96-cd0f139d6609"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The course follows a monthly zone'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"hi how are\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "ff96846b-f815-4f8d-b130-d12dfa716488"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi how are we\n",
            "hi how are we descend\n",
            "hi how are we descend from\n",
            "hi how are we descend from the\n",
            "hi how are we descend from the sunlit\n",
            "hi how are we descend from the sunlit surface\n",
            "hi how are we descend from the sunlit surface into\n",
            "hi how are we descend from the sunlit surface into the\n",
            "hi how are we descend from the sunlit surface into the abyss\n",
            "hi how are we descend from the sunlit surface into the abyss ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "JXsV4AnNXNnw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Py7o0rJJc5pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5e8cef-d0d5-4e9e-fed0-5e6072671a52"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 99.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bQnBuShXG5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}